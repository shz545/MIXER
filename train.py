import jax
import jax.numpy as jnp
import numpy as np
import jax.lax as lax
import optax
import time
from flax.training import train_state
from flax.training.train_state import TrainState
from flax.core import FrozenDict
from dataset import load_dataset
from utils import cutmix_data
from tqdm import tqdm  # æ”¾åœ¨æª”æ¡ˆæœ€ä¸Šæ–¹
from model import MlpMixer

import random

# ğŸ”¹ æŸ“è‰²é«”çµæ§‹
def sample_chromosome():
    return {
        "num_blocks": random.choice([4,6,8,10,12]),
        "patch_size": random.choice([4, 8]),
        "hidden_dim": random.choice([16, 32, 64, 128, 256]),
        "tokens_mlp_dim": random.choice([32, 64, 128, 256, 512]),
        "channels_mlp_dim": random.choice([32, 64, 128, 256, 512]),
        "dropout_rate": random.uniform(0.0, 0.5),
        "learning_rate": random.uniform(5e-4, 5e-2),
        "use_bn": random.choice([True])
    }

def mutate(chromosome):
    key = random.choice(list(chromosome.keys()))
    chromosome[key] = sample_chromosome()[key]
    return chromosome

def crossover(parent1, parent2):
    child = {}
    for key in parent1:
        child[key] = random.choice([parent1[key], parent2[key]])
    return child

# ğŸ”¹ æ“´å…… TrainState ä»¥æ”¯æ´ BatchNorm
class TrainState(train_state.TrainState):
    batch_stats: FrozenDict

# ğŸ”¹ Cross entropy lossï¼ˆlabel smoothingï¼‰
def cross_entropy_loss(logits, labels, smoothing=0.1):
    num_classes = logits.shape[-1]
    one_hot = jax.nn.one_hot(labels, num_classes)
    soft_labels = one_hot * (1 - smoothing) + smoothing / num_classes
    return optax.softmax_cross_entropy(logits, soft_labels).mean()

def cosine_annealing_with_restarts_schedule(
    base_lr, warmup_steps, initial_period, period_mult=2, eta_min=0.0
):
    def schedule(step):
        # Warmup phase
        def warmup_fn(_):
            return base_lr * step / warmup_steps

        def anneal_fn(_):
            # Remove warmup steps
            s = step - warmup_steps
            period = initial_period
            accumulated = 0

            def cond_fn(vals):
                s, accumulated, period = vals
                return s >= accumulated + period

            def body_fn(vals):
                s, accumulated, period = vals
                return s, accumulated + period, period * period_mult

            s, accumulated, period = lax.while_loop(cond_fn, body_fn, (s, accumulated, period))
            t_cur = s - accumulated
            cosine = jnp.cos(jnp.pi * t_cur / period)
            return eta_min + 0.5 * (base_lr - eta_min) * (1 + cosine)

        return lax.cond(step < warmup_steps, warmup_fn, anneal_fn, operand=None)

    return schedule

def create_train_state(
    rng, model, learning_rate, num_epochs=None, steps_per_epoch=None,
    warmup_steps=0, weight_decay=5e-5, initial_period=500, period_mult=2,
    eta_min=0.0, optimizer="adamw", momentum=0.9
):
    variables = model.init(rng, jnp.ones([1, 32, 32, 3]), train=True)
    params = variables['params']
    batch_stats = variables.get('batch_stats', FrozenDict())

    if num_epochs and steps_per_epoch:
        warmup_steps = 2 * steps_per_epoch
        schedule_fn = cosine_annealing_with_restarts_schedule(
            base_lr=learning_rate,
            warmup_steps=warmup_steps,
            initial_period=initial_period,
            period_mult=period_mult,
            eta_min=eta_min
        )
        schedule = schedule_fn  # ç›´æ¥ä¿ç•™åŸå§‹å‡½æ•¸

        if optimizer.lower() == "adamw":
            tx = optax.adamw(schedule, weight_decay=weight_decay)
        elif optimizer.lower() == "sgd":
            tx = optax.chain(
                optax.trace(decay=momentum, nesterov=True),
                optax.scale_by_schedule(schedule),
                optax.scale(-1.0)
            )
        else:
            raise ValueError(f"Unsupported optimizer: {optimizer}")
    else:
        schedule = None
        if optimizer.lower() == "adamw":
            tx = optax.adamw(learning_rate=learning_rate, weight_decay=weight_decay)
        elif optimizer.lower() == "sgd":
            tx = optax.sgd(learning_rate=learning_rate, momentum=momentum, nesterov=True)
        else:
            raise ValueError(f"Unsupported optimizer: {optimizer}")

    return TrainState.create(
        apply_fn=model.apply,
        params=params,
        tx=tx,
        batch_stats=batch_stats
    ), schedule

# ğŸ”¹ å–®æ­¥è¨“ç·´ï¼ˆåŠ å…¥ MixUp + BN æ›´æ–°ï¼‰
@jax.jit
def train_step(state, mixed_imgs, y_a, y_b, lam, labels, smoothing=0.1):

    def loss_fn(params):
        dropout_rng = jax.random.fold_in(jax.random.PRNGKey(0), state.step)
        variables = {'params': params, 'batch_stats': state.batch_stats}
        logits, new_model_state = state.apply_fn(
            variables,
            mixed_imgs,
            train=True,
            rngs={'dropout': dropout_rng},
            mutable=["batch_stats"]
        )
        loss_a = cross_entropy_loss(logits, y_a, smoothing)
        loss_b = cross_entropy_loss(logits, y_b, smoothing)
        loss = lam * loss_a + (1 - lam) * loss_b
        return loss, (logits, new_model_state)

    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)
    (loss, (logits, new_model_state)), grads = grad_fn(state.params)
    state = state.apply_gradients(grads=grads)
    state = state.replace(batch_stats=new_model_state["batch_stats"])
    acc = jnp.mean(jnp.argmax(logits, axis=-1) == labels)
    return state, {'loss': loss, 'accuracy': acc}

# ğŸ”¹ é©—è­‰æ­¥é©Ÿï¼ˆBN æ¨è«–æ¨¡å¼ï¼‰
def eval_step(state, batch, smoothing=0.1):
    imgs, labels = batch
    variables = {'params': state.params, 'batch_stats': state.batch_stats}
    logits = state.apply_fn(variables, imgs, train=False, mutable=False)
    loss = cross_entropy_loss(logits, labels, smoothing)
    acc = jnp.mean(jnp.argmax(logits, axis=-1) == labels)
    return {'loss': loss, 'accuracy': acc}

# ğŸ”¹ EarlyStopping æ©Ÿåˆ¶
class EarlyStopping:
    def __init__(self, patience=10, enabled=True):
        self.best_loss = float('inf')
        self.counter = 0
        self.patience = patience
        self.enabled = enabled

    def should_stop(self, val_loss):
        if not self.enabled:
            return False
        if val_loss < self.best_loss:
            self.best_loss = val_loss
            self.counter = 0
        else:
            self.counter += 1
        return self.counter >= self.patience

# ğŸ”¹ è³‡æ–™é›†åˆ†å‰²
def split_dataset(data, split_ratio=0.9):
    split_idx = int(len(data) * split_ratio)
    return data[:split_idx], data[split_idx:]

# ğŸ”¹ é©åˆåº¦å‡½æ•¸ï¼ˆGGAï¼‰
def fitness(chromosome, rng):
    start_time = time.time()  # é–‹å§‹è¨ˆæ™‚
    tqdm.write("ğŸ“Š é–‹å§‹è©•ä¼°")
    
    model = MlpMixer(
        num_classes=10,
        num_blocks=chromosome["num_blocks"],
        patch_size=chromosome["patch_size"],
        hidden_dim=chromosome["hidden_dim"],
        tokens_mlp_dim=chromosome["tokens_mlp_dim"],
        channels_mlp_dim=chromosome["channels_mlp_dim"],
        dropout_rate=chromosome["dropout_rate"],
        use_bn=chromosome["use_bn"]
    )

    batch_size = 128
    num_epochs = 12
    full_train_data = load_dataset(batch_size=batch_size, train=True)
    train_data, val_data = split_dataset(full_train_data, split_ratio=0.9)
    steps_per_epoch = len(train_data)
    warmup_steps = 2 * steps_per_epoch

    state, _ = create_train_state(
        rng, model,
        learning_rate=chromosome["learning_rate"],
        num_epochs=num_epochs,
        steps_per_epoch=steps_per_epoch,
        warmup_steps=warmup_steps,
        weight_decay=5e-5
    )

    for epoch in range(num_epochs):
        for batch in tqdm(train_data, desc=f"Train Epoch {epoch+1}/{num_epochs}", leave=False):
            imgs, labels = batch
            mixed_imgs, y_a, y_b, lam = cutmix_data(np.array(imgs), np.array(labels))
            state, metrics = train_step(state, mixed_imgs, y_a, y_b, lam, labels)

    val_acc = 0
    for batch in tqdm(val_data, desc="Validating", leave=False):
        metrics = eval_step(state, batch)
        val_acc += float(metrics['accuracy'])

    end_time = time.time()  # çµæŸè¨ˆæ™‚
    elapsed = end_time - start_time
    tqdm.write(f"â± å€‹é«”è¨“ç·´æ™‚é–“ï¼š{elapsed:.2f} ç§’")
    
    return val_acc / len(val_data), elapsed

# ğŸ”¹ GGA ä¸»æµç¨‹
def run_gga(pop_size=6, generations=5):
    rng = jax.random.PRNGKey(42)
    population = [sample_chromosome() for _ in range(pop_size)]

    tqdm.write("ğŸ”§ é ç†± JAX ç·¨è­¯å™¨...")

    total_start_time = time.time()  # æ•´é«”é–‹å§‹è¨ˆæ™‚

    for gen in range(generations):
        tqdm.write(f"\nğŸ“˜ Generation {gen+1}\n")

        scores = []
        times = []
        for i, ind in enumerate(tqdm(population, desc=f"Evaluating Gen {gen+1}", leave=True)):
            tqdm.write(f"ğŸ§¬ å€‹é«” {i+1} æŸ“è‰²é«”åƒæ•¸ï¼š{ind}")
            score, elapsed = fitness(ind, rng)
            scores.append(score)
            times.append(elapsed)
            tqdm.write(f"âœ… å€‹é«” {i+1} é©—è­‰æº–ç¢ºç‡: {score:.4f}")
            tqdm.write(f"â± è¨“ç·´æ™‚é–“: {elapsed:.2f} ç§’")
            tqdm.write("--------------------------------------------------------------------------------------------------------------------------------------")

        sorted_pop = [x for _, x in sorted(zip(scores, population), key=lambda pair: pair[0], reverse=True)]
        parents = sorted_pop[:2]

        best_score = max(scores)
        avg_time = sum(times) / len(times)
        tqdm.write(f"ğŸ… Gen {gen+1} æœ€ä½³æº–ç¢ºç‡: {best_score:.4f}")
        tqdm.write(f"ğŸ•’ Gen {gen+1} å¹³å‡è¨“ç·´æ™‚é–“: {avg_time:.2f} ç§’")

        new_population = []
        while len(new_population) < pop_size:
            child = crossover(parents[0], parents[1])
            child = mutate(child)
            new_population.append(child)
        population = new_population

    total_end_time = time.time()
    total_elapsed = total_end_time - total_start_time
    tqdm.write(f"\nâ³ æ‰€æœ‰ä¸–ä»£ç¸½è¨“ç·´æ™‚é–“: {total_elapsed:.2f} ç§’")

    best_chromosome = sorted_pop[0]
    tqdm.write("\nğŸ† æœ€ä½³æŸ“è‰²é«”åƒæ•¸ï¼š")
    for k, v in best_chromosome.items():
        tqdm.write(f"{k}: {v}")
    return best_chromosome
